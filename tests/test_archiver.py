"""
Tests for techcompressor.archiver module (folder/multi-file compression)
"""

import os
import tempfile
import shutil
import pytest
from pathlib import Path
from techcompressor.archiver import create_archive, extract_archive, list_contents


def test_create_and_extract_small_dir():
    """Test creating and extracting archive with nested folders and files."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "test.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        # Create test directory structure
        source_dir.mkdir()
        (source_dir / "file1.txt").write_text("Hello World")
        (source_dir / "file2.bin").write_bytes(b"\x00\x01\x02\x03\xFF")
        
        subdir = source_dir / "subdir"
        subdir.mkdir()
        (subdir / "nested.txt").write_text("Nested content")
        
        deeper = subdir / "deeper"
        deeper.mkdir()
        (deeper / "deep.txt").write_text("Deep nested file")
        
        # Create archive
        create_archive(source_dir, archive_path, algo="LZW", per_file=True)
        
        # Verify archive exists
        assert archive_path.exists()
        assert archive_path.stat().st_size > 0
        
        # Extract archive
        extract_archive(archive_path, extract_dir)
        
        # Verify extracted files
        assert (extract_dir / "file1.txt").exists()
        assert (extract_dir / "file1.txt").read_text() == "Hello World"
        
        assert (extract_dir / "file2.bin").exists()
        assert (extract_dir / "file2.bin").read_bytes() == b"\x00\x01\x02\x03\xFF"
        
        assert (extract_dir / "subdir" / "nested.txt").exists()
        assert (extract_dir / "subdir" / "nested.txt").read_text() == "Nested content"
        
        assert (extract_dir / "subdir" / "deeper" / "deep.txt").exists()
        assert (extract_dir / "subdir" / "deeper" / "deep.txt").read_text() == "Deep nested file"


def test_single_file_archive():
    """Test archiving a single file instead of directory."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_file = Path(tmpdir) / "single.txt"
        archive_path = Path(tmpdir) / "single.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_file.write_text("Single file content")
        
        # Create archive from single file
        create_archive(source_file, archive_path, algo="HUFFMAN")
        
        assert archive_path.exists()
        
        # Extract
        extract_archive(archive_path, extract_dir)
        
        # Verify - file should have same name
        assert (extract_dir / "single.txt").exists()
        assert (extract_dir / "single.txt").read_text() == "Single file content"


def test_list_contents():
    """Test listing archive contents without extraction."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "test.tc"
        
        # Create test files
        source_dir.mkdir()
        (source_dir / "file1.txt").write_text("Content 1")
        (source_dir / "file2.txt").write_text("Content 2 is longer")
        
        subdir = source_dir / "sub"
        subdir.mkdir()
        (subdir / "file3.txt").write_text("Content 3")
        
        # Create archive
        create_archive(source_dir, archive_path, algo="LZW")
        
        # List contents
        contents = list_contents(archive_path)
        
        # Verify
        assert len(contents) == 3
        
        # Check names are present
        names = [entry['name'] for entry in contents]
        assert "file1.txt" in names
        assert "file2.txt" in names
        assert str(Path("sub") / "file3.txt") in names or "sub/file3.txt" in names
        
        # Check sizes
        for entry in contents:
            assert 'size' in entry
            assert 'compressed_size' in entry
            assert 'mtime' in entry
            assert 'mode' in entry
            assert entry['size'] > 0


def test_per_file_vs_single_stream():
    """Compare per-file and single-stream compression modes."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_per_file = Path(tmpdir) / "per_file.tc"
        archive_single = Path(tmpdir) / "single.tc"
        extract_per = Path(tmpdir) / "extract_per"
        extract_single = Path(tmpdir) / "extract_single"
        
        # Create test data with repetitive patterns (favors single-stream)
        source_dir.mkdir()
        for i in range(5):
            (source_dir / f"file{i}.txt").write_text("REPEAT" * 100)
        
        # Create both archive types
        create_archive(source_dir, archive_per_file, algo="DEFLATE", per_file=True)
        create_archive(source_dir, archive_single, algo="DEFLATE", per_file=False)
        
        # Both should exist
        assert archive_per_file.exists()
        assert archive_single.exists()
        
        # Single-stream typically has better compression for repetitive data
        # (but not guaranteed, so just verify both work)
        
        # Extract both
        extract_archive(archive_per_file, extract_per)
        extract_archive(archive_single, extract_single)
        
        # Verify both extracted correctly
        for i in range(5):
            assert (extract_per / f"file{i}.txt").read_text() == "REPEAT" * 100
            assert (extract_single / f"file{i}.txt").read_text() == "REPEAT" * 100


def test_large_file_streaming():
    """Test archiving and extracting large file (~20MB) with streaming."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "large.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        
        # Create ~20MB file with random data
        large_file = source_dir / "large_file.bin"
        large_size = 20 * 1024 * 1024  # 20 MB
        
        # Write in chunks to avoid memory issues
        with open(large_file, 'wb') as f:
            remaining = large_size
            chunk_size = 1024 * 1024  # 1 MB chunks
            while remaining > 0:
                chunk = os.urandom(min(chunk_size, remaining))
                f.write(chunk)
                remaining -= len(chunk)
        
        original_size = large_file.stat().st_size
        assert original_size >= large_size
        
        # Create archive (should handle streaming)
        create_archive(source_dir, archive_path, algo="LZW", per_file=True)
        
        assert archive_path.exists()
        
        # Extract
        extract_archive(archive_path, extract_dir)
        
        extracted_file = extract_dir / "large_file.bin"
        assert extracted_file.exists()
        
        # Verify size matches (content verification would be too slow)
        assert extracted_file.stat().st_size == original_size


def test_encrypted_archive():
    """Test creating and extracting encrypted archive."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "encrypted.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        (source_dir / "secret.txt").write_text("Confidential Data")
        (source_dir / "data.bin").write_bytes(b"Secret Binary \x00\xFF")
        
        password = "test_password_123"
        
        # Create encrypted archive
        create_archive(source_dir, archive_path, algo="DEFLATE", password=password)
        
        assert archive_path.exists()
        
        # Extract with correct password
        extract_archive(archive_path, extract_dir, password=password)
        
        # Verify content
        assert (extract_dir / "secret.txt").read_text() == "Confidential Data"
        assert (extract_dir / "data.bin").read_bytes() == b"Secret Binary \x00\xFF"


def test_encrypted_archive_wrong_password():
    """Test that wrong password raises error."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "encrypted.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        (source_dir / "file.txt").write_text("Content")
        
        correct_password = "correct_pass"
        wrong_password = "wrong_pass"
        
        # Create encrypted archive
        create_archive(source_dir, archive_path, password=correct_password)
        
        # Try to extract with wrong password
        with pytest.raises(ValueError, match="Invalid password or corrupted data"):
            extract_archive(archive_path, extract_dir, password=wrong_password)


def test_encrypted_archive_no_password():
    """Test that encrypted archive without password raises error."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "encrypted.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        (source_dir / "file.txt").write_text("Content")
        
        # Create encrypted archive
        create_archive(source_dir, archive_path, password="secret")
        
        # Try to extract without password
        with pytest.raises(ValueError, match="encrypted but no password provided"):
            extract_archive(archive_path, extract_dir)


def test_path_traversal_protection():
    """Test that extraction prevents path traversal attacks."""
    with tempfile.TemporaryDirectory() as tmpdir:
        # We'll manually create a malicious archive structure
        # by modifying the entry table to contain ../ in paths
        
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "test.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        (source_dir / "normal.txt").write_text("Normal file")
        
        # Create normal archive first
        create_archive(source_dir, archive_path, algo="LZW")
        
        # For this test, we'll try extracting with a simulated attack
        # by creating an entry with ../ in the name
        # The sanitizer should catch this
        
        # Test the sanitizer directly through extraction
        # Create a structure that would escape if not sanitized
        source_attack = Path(tmpdir) / "attack_source"
        source_attack.mkdir()
        
        # Try to create file with ../ in name (filesystem won't allow it,
        # but we test the extraction sanitizer)
        (source_attack / "safe.txt").write_text("Safe content")
        
        archive_attack = Path(tmpdir) / "attack.tc"
        create_archive(source_attack, archive_attack)
        
        # Extract should work normally
        extract_archive(archive_attack, extract_dir)
        
        # Verify file is in correct location (not escaped)
        assert (extract_dir / "safe.txt").exists()
        
        # The path should be inside extract_dir
        assert (extract_dir / "safe.txt").resolve().is_relative_to(extract_dir.resolve())


def test_empty_directory():
    """Test that empty directory raises error."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "empty"
        archive_path = Path(tmpdir) / "test.tc"
        
        source_dir.mkdir()
        
        # Should raise error for empty directory
        with pytest.raises(ValueError, match="No files found"):
            create_archive(source_dir, archive_path)


def test_nonexistent_source():
    """Test that nonexistent source raises error."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "nonexistent"
        archive_path = Path(tmpdir) / "test.tc"
        
        with pytest.raises(FileNotFoundError):
            create_archive(source_dir, archive_path)


def test_nonexistent_archive():
    """Test that nonexistent archive raises error."""
    with tempfile.TemporaryDirectory() as tmpdir:
        archive_path = Path(tmpdir) / "nonexistent.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        with pytest.raises(FileNotFoundError):
            extract_archive(archive_path, extract_dir)
        
        with pytest.raises(FileNotFoundError):
            list_contents(archive_path)


def test_metadata_preservation():
    """Test that file metadata (mtime, mode) is preserved."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "test.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        test_file = source_dir / "test.txt"
        test_file.write_text("Test content")
        
        # Set specific mtime
        import time
        test_mtime = time.time() - 86400  # 1 day ago
        os.utime(test_file, (test_mtime, test_mtime))
        
        # Get original metadata
        original_stat = test_file.stat()
        original_mtime = int(original_stat.st_mtime)
        
        # Create and extract archive
        create_archive(source_dir, archive_path)
        extract_archive(archive_path, extract_dir)
        
        # Check extracted metadata
        extracted_file = extract_dir / "test.txt"
        extracted_stat = extracted_file.stat()
        extracted_mtime = int(extracted_stat.st_mtime)
        
        # Times should match (within 1 second tolerance)
        assert abs(extracted_mtime - original_mtime) <= 1


def test_binary_data():
    """Test archiving binary data with all byte values."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "binary.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        
        # Create file with all possible byte values
        binary_data = bytes(range(256)) * 100
        (source_dir / "binary.dat").write_bytes(binary_data)
        
        # Archive and extract
        create_archive(source_dir, archive_path, algo="DEFLATE")
        extract_archive(archive_path, extract_dir)
        
        # Verify binary data integrity
        extracted_data = (extract_dir / "binary.dat").read_bytes()
        assert extracted_data == binary_data


def test_unicode_filenames():
    """Test archiving files with unicode names."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "unicode.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        
        # Create files with unicode names
        (source_dir / "test_Ñ„Ð°Ð¹Ð».txt").write_text("Russian")
        (source_dir / "æµ‹è¯•æ–‡ä»¶.txt").write_text("Chinese")
        (source_dir / "test_ðŸŽ‰.txt").write_text("Emoji")
        
        # Archive and extract
        create_archive(source_dir, archive_path)
        extract_archive(archive_path, extract_dir)
        
        # Verify files exist with correct names
        assert (extract_dir / "test_Ñ„Ð°Ð¹Ð».txt").read_text() == "Russian"
        assert (extract_dir / "æµ‹è¯•æ–‡ä»¶.txt").read_text() == "Chinese"
        assert (extract_dir / "test_ðŸŽ‰.txt").read_text() == "Emoji"


def test_different_algorithms():
    """Test archiving with different compression algorithms."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        
        source_dir.mkdir()
        (source_dir / "file.txt").write_text("Test content" * 100)
        
        for algo in ["LZW", "HUFFMAN", "DEFLATE"]:
            archive_path = Path(tmpdir) / f"archive_{algo}.tc"
            extract_dir = Path(tmpdir) / f"extract_{algo}"
            
            # Create and extract
            create_archive(source_dir, archive_path, algo=algo)
            extract_archive(archive_path, extract_dir)
            
            # Verify
            assert (extract_dir / "file.txt").read_text() == "Test content" * 100


def test_recursion_prevention():
    """Test that creating archive inside source directory is prevented."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        source_dir.mkdir()
        
        # Try to create archive inside source directory
        archive_path = source_dir / "archive.tc"
        
        (source_dir / "file.txt").write_text("Content")
        
        # Should raise error about recursion
        with pytest.raises(ValueError, match="infinite recursion"):
            create_archive(source_dir, archive_path)


def test_stored_mode_for_incompressible_files():
    """Test that incompressible files are stored uncompressed (v2 format)."""
    import os
    
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "test.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        # Create test directory with mixed compressible/incompressible files
        source_dir.mkdir()
        
        # Highly compressible file (repetitive text)
        compressible_data = b"A" * 10000
        (source_dir / "compressible.txt").write_bytes(compressible_data)
        
        # Incompressible file (random data, simulates PNG/encrypted file)
        incompressible_data = os.urandom(10000)
        (source_dir / "incompressible.bin").write_bytes(incompressible_data)
        
        # Create archive with AUTO mode
        create_archive(source_dir, archive_path, algo="AUTO", per_file=True)
        
        # Verify archive exists and is smaller than naive compression
        assert archive_path.exists()
        archive_size = archive_path.stat().st_size
        
        # Archive should be significantly smaller than sum of files
        # because compressible file shrinks and incompressible is stored as-is
        total_original = len(compressible_data) + len(incompressible_data)
        
        # Archive overhead is minimal, incompressible stored, compressible shrunk
        # Archive should be roughly: incompressible_size + small_compressed + overhead
        # Should definitely be less than 2x the incompressible file size
        assert archive_size < len(incompressible_data) * 1.5, \
            f"Archive {archive_size} should be close to incompressible size {len(incompressible_data)}"
        
        # Extract and verify integrity
        extract_archive(archive_path, extract_dir)
        
        # Verify files match exactly
        assert (extract_dir / "compressible.txt").read_bytes() == compressible_data
        assert (extract_dir / "incompressible.bin").read_bytes() == incompressible_data


def test_stored_mode_backward_compatibility():
    """Test that v2 archives maintain backward-compatible extraction."""
    with tempfile.TemporaryDirectory() as tmpdir:
        source_dir = Path(tmpdir) / "source"
        archive_path = Path(tmpdir) / "test.tc"
        extract_dir = Path(tmpdir) / "extracted"
        
        source_dir.mkdir()
        
        # Create file that will be stored (incompressible)
        data = os.urandom(1000)
        (source_dir / "file.bin").write_bytes(data)
        
        # Create archive
        create_archive(source_dir, archive_path, algo="AUTO")
        
        # Extract and verify
        extract_archive(archive_path, extract_dir)
        assert (extract_dir / "file.bin").read_bytes() == data
        
        # List contents should work
        contents = list_contents(archive_path)
        assert len(contents) == 1
        assert contents[0]['name'] == 'file.bin'
        assert contents[0]['size'] == len(data)

